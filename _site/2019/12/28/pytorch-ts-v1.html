<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />

  <title>
    
      Time Series & PyTorch - Training network to compute moving average &middot; krzjoa
    
  </title>

  


  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css" />
  

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface" />

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/favicon.png" />
<link rel="shortcut icon" href="/favicon.ico" />

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml" />

  <!-- Additional head bits without overriding original head -->
</head>


  <body class="post">

    <div id="sidebar">
  <header>
    <div class="site-title">
      <a href="/">
        
          <span class="back-arrow icon"><svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
  <path d="M0 0h24v24H0z" fill="none"/>
  <path d="M20 11H7.83l5.59-5.59L12 4l-8 8 8 8 1.41-1.41L7.83 13H20v-2z"/>
</svg></span>
        
        krzjoa
      </a>
    </div>
    <p class="lead">Getting at the Truth</p>
  </header>
  <nav id="sidebar-nav-links">
  
    <a class="home-link "
        href="/">Home</a>
  
  

  

  


  
    
  

  

  
    
  

  
    
      <a class="page-link "
          href="/projects.html">Projects</a>
    
  

  
    
      <a class="page-link "
          href="/publications.html">Publications</a>
    
  

  
    
  

  
    
  


  


  
    
  

  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  <!--p><a href="/calc/calc.html">CNN Calculator</a></p-->
  <!-- Optional additional links to insert in sidebar nav -->
</nav>


  

  <nav id="sidebar-icon-links">
  

  <a id="subscribe-link"
     class="icon" title="Subscribe" aria-label="Subscribe"
     href="/feed.xml">
    <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <circle cx="6.18" cy="17.82" r="2.18"/>
    <path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/>
</svg>
  </a>

  
  
  
  

  
    <a id="tags-link"
       class="icon"
       title="Tags" aria-label="Tags"
       href="/tags.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
    </a>
  

  
    <a id="search-link"
       class="icon"
       title="Search" aria-label="Search"
       href="/search.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
    </a>
  

  <a id="github-link"
    class="icon" title="Github" aria-label="Github"
    href="https://github.com/krzjoa">
  <svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 28" height="24" width="28"><path d="M12 2c6.625 0 12 5.375 12 12 0 5.297-3.437 9.797-8.203 11.391-0.609 0.109-0.828-0.266-0.828-0.578 0-0.391 0.016-1.687 0.016-3.297 0-1.125-0.375-1.844-0.812-2.219 2.672-0.297 5.484-1.313 5.484-5.922 0-1.313-0.469-2.375-1.234-3.219 0.125-0.313 0.531-1.531-0.125-3.187-1-0.313-3.297 1.234-3.297 1.234-0.953-0.266-1.984-0.406-3-0.406s-2.047 0.141-3 0.406c0 0-2.297-1.547-3.297-1.234-0.656 1.656-0.25 2.875-0.125 3.187-0.766 0.844-1.234 1.906-1.234 3.219 0 4.594 2.797 5.625 5.469 5.922-0.344 0.313-0.656 0.844-0.766 1.609-0.688 0.313-2.438 0.844-3.484-1-0.656-1.141-1.844-1.234-1.844-1.234-1.172-0.016-0.078 0.734-0.078 0.734 0.781 0.359 1.328 1.75 1.328 1.75 0.703 2.141 4.047 1.422 4.047 1.422 0 1 0.016 1.937 0.016 2.234 0 0.313-0.219 0.688-0.828 0.578-4.766-1.594-8.203-6.094-8.203-11.391 0-6.625 5.375-12 12-12zM4.547 19.234c0.031-0.063-0.016-0.141-0.109-0.187-0.094-0.031-0.172-0.016-0.203 0.031-0.031 0.063 0.016 0.141 0.109 0.187 0.078 0.047 0.172 0.031 0.203-0.031zM5.031 19.766c0.063-0.047 0.047-0.156-0.031-0.25-0.078-0.078-0.187-0.109-0.25-0.047-0.063 0.047-0.047 0.156 0.031 0.25 0.078 0.078 0.187 0.109 0.25 0.047zM5.5 20.469c0.078-0.063 0.078-0.187 0-0.297-0.063-0.109-0.187-0.156-0.266-0.094-0.078 0.047-0.078 0.172 0 0.281s0.203 0.156 0.266 0.109zM6.156 21.125c0.063-0.063 0.031-0.203-0.063-0.297-0.109-0.109-0.25-0.125-0.313-0.047-0.078 0.063-0.047 0.203 0.063 0.297 0.109 0.109 0.25 0.125 0.313 0.047zM7.047 21.516c0.031-0.094-0.063-0.203-0.203-0.25-0.125-0.031-0.266 0.016-0.297 0.109s0.063 0.203 0.203 0.234c0.125 0.047 0.266 0 0.297-0.094zM8.031 21.594c0-0.109-0.125-0.187-0.266-0.172-0.141 0-0.25 0.078-0.25 0.172 0 0.109 0.109 0.187 0.266 0.172 0.141 0 0.25-0.078 0.25-0.172zM8.937 21.438c-0.016-0.094-0.141-0.156-0.281-0.141-0.141 0.031-0.234 0.125-0.219 0.234 0.016 0.094 0.141 0.156 0.281 0.125s0.234-0.125 0.219-0.219z"></path>
</svg>

</a>

<!--a id="rbloggers-link"
    class="icon" title="R-bloggers" aria-label="R-bloggers"
    href="https://www.r-bloggers.com">
  <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   xmlns:osb="http://www.openswatchbook.org/uri/2009/osb"
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   id="svg12"
   preserveAspectRatio="xMidYMid meet"
   viewBox="0 0 400.000000 400.000000"
   height="400.000000pt"
   width="400.000000pt"
   version="1.0"
   sodipodi:docname="blg2.svg"
   inkscape:version="0.92.3 (2405546, 2018-03-11)">
  <metadata
     id="metadata18">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title />
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <defs
     id="defs16">
    <linearGradient
       id="linearGradient816"
       osb:paint="solid">
      <stop
         style="stop-color:#000000;stop-opacity:1;"
         offset="0"
         id="stop814" />
    </linearGradient>
  </defs>
  <g
     style="fill-opacity:1;fill-rule:nonzero;fill:#f2f2f2"
     id="g10"
     stroke="none"
     fill="#000000"
     transform="translate(0.000000,400.000000) scale(0.100000,-0.100000)">
    <path
       style="fill-opacity:1;fill-rule:nonzero;fill:#f2f2f2"
       d="m 1605,2599 c -144,-34 -210,-202 -130,-330 17,-26 78,-65 130,-84 47,-16 53,-16 109,0 166,48 223,240 106,355 -55,54 -138,76 -215,59 z m -167,775 c -7,-6 -12,-333 -5,-334 1,-1 31,-3 67,-6 142,-11 277,-54 404,-128 84,-50 217,-177 276,-265 77,-115 130,-269 145,-423 l 7,-68 h 169 169 v 58 c 0,135 -47,322 -120,477 -136,292 -401,527 -708,629 -128,43 -384,81 -404,60 z m -603,1 c -48,-17 -80,-52 -94,-103 -14,-49 -15,-3146 -1,-3171 19,-36 68,-46 225,-46 125,0 155,3 183,18 17,10 33,19 34,20 2,1 5,328 8,727 l 5,725 179,3 c 305,4 438,-34 578,-167 133,-125 177,-210 434,-845 107,-265 182,-438 195,-448 37,-31 97,-40 243,-36 175,4 200,13 204,76 3,46 -38,155 -228,602 -51,118 -108,253 -127,300 -127,309 -270,509 -431,603 -63,37 -73,52 -40,62 53,16 165,70 236,113 72,43 212,165 212,183 0,5 -126,9 -281,9 h -280 l -71,-30 c -135,-58 -175,-63 -515,-68 l -313,-4 v 565 566 l 43,3 42,3 v 175 175 l -200,2 c -152,2 -210,-1 -240,-12 z m 607,355 c 2,-113 6,-164 14,-163 23,4 212,-18 283,-34 107,-23 391,-135 391,-154 0,-5 4,-9 10,-9 18,0 165,-105 235,-167 140,-126 214,-226 336,-448 32,-58 72,-175 89,-260 7,-33 16,-69 20,-80 10,-23 18,-72 26,-172 l 7,-73 h 165 165 l -7,73 c -13,147 -41,313 -66,392 -5,17 -17,55 -26,85 -18,63 -159,356 -175,366 -6,3 -30,36 -53,73 -75,115 -235,281 -356,368 -36,26 -71,53 -78,60 -17,16 -189,113 -202,113 -5,0 -10,5 -10,10 0,6 -7,10 -15,10 -8,0 -15,4 -15,9 0,5 -10,11 -22,14 -13,3 -88,28 -168,55 -170,58 -328,90 -458,94 l -92,3 z"
       id="path8" />
  </g>
</svg>

</a>--

<!--a id="linkedin-link"
    class="icon" title="LinkedIn" aria-label="LinkedIn"
    href="https://linkedin.com/in/krzysztof-joachimiak">
  <?xml version="1.0" encoding="iso-8859-1"?>
<!-- Generator: Adobe Illustrator 16.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 490.732 490.732" style="enable-background:new 0 0 490.732 490.732;"
	 xml:space="preserve">
<g>
	<g>
		<path d="M472.366,0.003H18.36C8.219,0.003,0,8.222,0,18.363v454.005c0,10.143,8.219,18.361,18.36,18.361h454.012
			c10.142,0,18.36-8.219,18.36-18.361V18.363C490.727,8.222,482.507,0.003,472.366,0.003z M130.375,403.808
			c0,6.762-5.478,12.238-12.24,12.238H69.132c-6.756,0-12.24-5.477-12.24-12.238V189.625c0-6.763,5.484-12.24,12.24-12.24h49.003
			c6.762,0,12.24,5.477,12.24,12.24V403.808z M130.375,127.482c0,6.763-5.478,12.24-12.24,12.24H69.132
			c-6.756,0-12.24-5.478-12.24-12.24V83.969c0-6.763,5.484-12.24,12.24-12.24h49.003c6.762,0,12.24,5.477,12.24,12.24V127.482z
			 M433.835,403.808c0,6.762-5.483,12.238-12.24,12.238h-49.003c-6.763,0-12.24-5.477-12.24-12.238v-90.436
			c0-29.988-1.566-49.383-4.712-58.189c-3.14-8.807-8.237-15.649-15.3-20.526c-7.062-4.884-15.558-7.32-25.496-7.32
			c-12.729,0-24.149,3.488-34.26,10.459c-10.11,6.977-17.038,16.211-20.79,27.717c-3.745,11.506-5.618,32.779-5.618,63.807v74.488
			c0,6.762-5.483,12.238-12.24,12.238h-49.003c-6.756,0-12.24-5.477-12.24-12.238V189.625c0-6.763,5.483-12.24,12.24-12.24h43.771
			c6.763,0,12.24,5.477,12.24,12.24v16.316c0,6.763,3.312,7.852,7.858,2.852c22.864-25.123,50.753-37.687,83.673-37.687
			c16.212,0,31.028,2.919,44.455,8.758c13.422,5.838,23.58,13.292,30.466,22.356c6.885,9.063,11.683,19.351,14.382,30.857
			c2.699,11.505,4.058,27.98,4.058,49.426V403.808L433.835,403.808z"/>
	</g>
</g>
</svg>

</a><!-- Optional additional links to insert for icons links -->

</nav>

  <p>
  &copy; 2020.
  <a href="/LICENSE.md">MIT License.</a>
</p>

  <a href="https://www.r-bloggers.com/" style="font-size:12px">R-bloggers</a> <a href="https://www.rweekly.org/" style="font-size:12px">RWeekly</a>
</div>


    <main class="container">
      <header>
  <h1 class="post-title">Time Series & PyTorch - Training network to compute moving average</h1>
</header>
<div class="content">
  <div class="post-meta">
  <span class="post-date">28 Dec 2019</span>
  <span class="post-categories">
    
  </span>
</div>


  <div class="post-body">
    <p>When it comes to applying neural networks to Time Series processing (or other kind of sequential data), first words that we’ll probably think of are <strong>recurrent</strong> and <strong>convolutional</strong> layers. That’s absolutely right! In this post we’ll pass, step-by-step, through one of the simpliest examples of convolutional layer application i.e. training network to compute moving average. Such example may seem to not be practical, however its simplicity allows us to trace whole process and understand, how to control network’s behaviour, to model the way the network works.</p>

<h3 id="1-downloading-the-data">1. Downloading the data</h3>
<p>First thing we have to do is to download or create fake time serie dataset. Let get a Shampoo sales dataset published by Rob Hyndman in his <strong>R package</strong> <code class="highlighter-rouge">fma</code> (which was a software appedix for the book <em>Forecasting: Methods and Applications</em>). Originally this dataset can be found inside R script, but as we work with a Python libary PyTorch, it be better for us to load this data from csv file. Such file can be found, for instance, <a href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/shampoo.csv">here</a>. Supposing we work in <strong>Jupyter Notebook</strong> on Linux, we can fetch this data running following command:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">## Download dataset</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="o">.</span><span class="n">githubusercontent</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">jbrownlee</span><span class="o">/</span><span class="n">Datasets</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">shampoo</span><span class="o">.</span><span class="n">csv</span>
</code></pre></div></div>

<h3 id="2-loading-data-and-simple-visualization">2. Loading data and simple visualization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"shampoo.csv"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Sales'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>         
</code></pre></div></div>
<p><img src="https://raw.githubusercontent.com/krzjoa/krzjoa.github.io/master/assets/img/2019-19-28-pytorch-ts-v1/plot.png" alt="png" /></p>

<p>In this plot we can see an increasing trend, but in this excercise, data characterics make no diffeence for us.</p>

<h3 id="3-1-d-convolution-in-pytorch-lightning-quick-intro-or-reminder">3. 1-d convolution in PyTorch: lightning-quick intro (or reminder)</h3>

<p>In the case of <strong>univariate time series</strong>, one-dimensional convolution is a sliding window applied over time series, an operation which consist of multiplications and additions. It was intuitively illustrated on the gif below.</p>

<center>
<img src="https://raw.githubusercontent.com/krzjoa/krzjoa.github.io/master/assets/img/2019-19-28-pytorch-ts-v1/conv1d.gif" width="400" />
Source: https://blog.floydhub.com/reading-minds-with-deep-learning/
</center>

<p>As you can see, output depend on input and <strong>kernel</strong> values. Defining proper kernel, we can apply the operation we want. For example, using a <strong>(0.5, 0.5)</strong> kernel, it will give us a two-element moving average. To test that, let’s do a simple experiment.</p>

<h3 id="4-computing-moving-average-with-pandas">4. Computing moving average with <code class="highlighter-rouge">pandas</code></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ts</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Sales</span>
<span class="n">ts</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0    266.0
1    145.9
2    183.1
3    119.3
4    180.3
5    168.5
6    231.8
7    224.5
8    192.8
9    122.9
Name: Sales, dtype: float64
</code></pre></div></div>

<p>Using <code class="highlighter-rouge">pandas</code>, we can compute moving average by combining <code class="highlighter-rouge">rolling</code> and <code class="highlighter-rouge">mean</code> method calls. We use <code class="highlighter-rouge">head</code> method as well, to limit the output. By the way, this example shows the object-oriented nature of <code class="highlighter-rouge">pandas</code>, which allows us to chain following methodc calls. Other fact that is worth to mention is a <strong>NaN</strong> occurrence in the first row. It’s because we can’t compute moving avearge for the first element if we haven’t added any padding on the beginnng of the array; moreover, <code class="highlighter-rouge">pandas</code> keeps the input’s length, so the first element has no value.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># rolling(2) means that we use a sliding window of length 2</span>
<span class="n">ts</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0       NaN
1    205.95
2    164.50
3    151.20
4    149.80
5    174.40
6    200.15
7    228.15
8    208.65
9    157.85
Name: Sales, dtype: float64 ### 5. Computing moving average with PyTorch
</code></pre></div></div>

<p>Now, let’s reproduce this result using 1-dimensional convolution from PyTorch.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ts</span><span class="p">))</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>36
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ts_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>
<p>Let’s stop here for a moment. If you are not familiar with deep learning frameworks, you would be quite confused because of this <code class="highlighter-rouge">reshape</code> operation. What did we do above? We created a <strong>3-dimensional tensor</strong>; each number in <code class="highlighter-rouge">reshape</code> function describes respectively:</p>

<ol>
  <li>number of samples</li>
  <li>number of channels</li>
  <li>length of time series</li>
</ol>

<p>Meaning of this values requires some explanation.</p>

<ol>
  <li><strong>Number of samples</strong> is the number of time series we are working on. As we want to perform computations for one time series only, the value must equal one.</li>
  <li><strong>Number of channels</strong> is is the number of <strong>features</strong> or (independent) <strong>variables</strong>. We don’t have any parallel variables contaning information about, say, temperature or population. It’s clear that this value must equal one too.</li>
  <li><strong>Length of time series</strong>. Accordingly to Python tensor reshaping convention, minus one means <em>infer value for this dimension</em>. If one-dimensional time series length has 36 elements, after reshaping it to three-dimensional tensor with <em>number_of_samples</em> = 1 and <em>number_of_channels</em> = 1, the last value will be equal to 36.</li>
</ol>

<p>We have to do the same with the kernel.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">kernel</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">kernel_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">F</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span><span class="n">ts_tensor</span><span class="p">,</span> <span class="n">kernel_tensor</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[[205.9500, 164.5000, 151.2000, 149.8000, 174.4000, 200.1500, 228.1500,
          208.6500, 157.8500, 229.7000, 261.2000, 190.1000, 171.9000, 179.8000,
          241.7000, 232.3500, 239.2000, 256.5000, 264.8000, 296.7500, 355.7500,
          343.0500, 303.4000, 341.0000, 390.0500, 378.1500, 377.6000, 420.3000,
          419.3500, 506.4500, 491.5500, 544.8000, 578.6500, 528.3000, 614.1000]]])
</code></pre></div></div>

<p>As we can observe, the result is identical with values returned by <code class="highlighter-rouge">pandas</code> methods. The only difference is lack of <strong>NaN</strong> on the beginning.</p>

<h3 id="6-learning-a-network-which-computes-moving-average">6. Learning a network, which computes moving average</h3>

<p>Now, let’s get to the point and train the network on the fully controllable example. I’ve called in this manner to distinguish it from the real-life ones. In most cases, when we train a machine learning model, we don’t know the optimal parameter values. We are just trying to choose the best ones, but have no guarantee that they are globally optimal. Here, the optimal kernel value is known and should equal <strong>[0.2, 0.2, 0.2, 0.2, 0.2]</strong>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Sales</span>
<span class="n">X_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>In the step below, we are preparing <strong>targets</strong> (<strong>labels</strong>), which equals to the five-element moving average.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Sales</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">4</span><span class="p">:,</span> <span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_tensor</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[[178.9200, 159.4200, 176.6000, 184.8800, 199.5800, 188.1000, 221.7000,
          212.5200, 206.4800, 197.8200, 215.2600, 202.6200, 203.7200, 222.2600,
          237.5600, 256.2600, 259.5800, 305.6200, 301.1200, 324.3800, 331.6000,
          361.7000, 340.5600, 375.5200, 387.3200, 406.8600, 433.8800, 452.2200,
          500.7600, 515.5600, 544.3400, 558.6200]]])
</code></pre></div></div>

<p>We are building a one-layer convlutional neural network. It’s good to highlight, that <strong>we don’t use any nonlinear activation function</strong>. Last numerical value describes the length of the kernel, <em>padding_mode = ‘valid’</em> means that we don’t add any padding to the input, so we have to expect that output will be “trimmed”.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Building a network</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">padding_mode</span> <span class="o">=</span> <span class="s">"valid"</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>
<p>Kernel is already initialized with, assume it for simplicity, <em>random</em> values.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Initial values</span>
<span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[[-0.26035744, -0.03702363,  0.36730862, -0.02416185,
          0.13382941]]], dtype=float32)
</code></pre></div></div>

<p>We can perfom a convolution operation using this random value, calling <strong>net.forward()</strong> or simply <strong>net()</strong> (because Conv1d layer is a <a href="https://stackoverflow.com/questions/5824881/python-call-special-method-practical-example/5826283">callable object</a>). This two operations are equivalent.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">net</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor([[[ 13.8443,  17.2486,  41.0878,  48.5995,  52.3392,  41.7977,  44.2186,
           -3.6977,  90.3636,  39.1391,   1.3805,  30.8177,  40.0606,  87.4678,
           28.7942,  62.3456,  54.0152,  77.8429,  61.6129, 104.4986,  43.2576,
           56.9010,  74.8728, 111.2240,  54.3756,  83.8423, 115.3400,  72.0719,
          172.1338,  61.6583, 151.8888, 115.7389]]],
       grad_fn=&lt;SqueezeBackward1&gt;) We are initializing an optimizer object. I highly encourage you to experiment and start with **SGD** which may do not converge.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Training a network</span>
<span class="c"># optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</code></pre></div></div>

<p>Here, he have only one example so it does not make sense to divide training into epochs</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">):</span>
    <span class="c"># Zeroing gradients. For more,</span>
    <span class="c"># see: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c"># Forward propagation</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)</span>  

    <span class="c"># Mean squared error</span>
    <span class="n">loss_value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">outputs</span> <span class="o">-</span> <span class="n">y_tensor</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="c"># Computing gradients</span>
    <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c"># Changing network parameters with optimizer</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c"># Extractin loss value from tensor</span>
    <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss_value</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'[</span><span class="si">%</span><span class="s">d] loss: </span><span class="si">%.3</span><span class="s">f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">loss_value</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
        <span class="k">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0] loss: 65233.992
[[[-0.25035745 -0.02702364  0.3773086  -0.01416185  0.14382942]]]
[50] loss: 766.905
[[[-0.10564941  0.11878491  0.5043409   0.1344783   0.27711937]]]
[100] loss: 543.447
[[[-0.0883443   0.13628373  0.48577502  0.15751141  0.2710214 ]]]
[150] loss: 426.048
[[[-0.0724933   0.14859414  0.45826674  0.1760565   0.25820443]]]
[200] loss: 328.581
[[[-0.05417605  0.15856615  0.4295487   0.1921131   0.2450627 ]]]
[250] loss: 251.294
[[[-0.03332883  0.1663786   0.40218312  0.20528159  0.23343563]]]
[300] loss: 191.313
[[[-0.01093305  0.17196906  0.37692106  0.21512112  0.2236998 ]]]
[350] loss: 144.881
[[[0.01206546 0.17570996 0.3540248  0.22179407 0.21593276]]]
[400] loss: 108.854
[[[0.03480669 0.1781194  0.33345547 0.225752   0.2099969 ]]]
[450] loss: 80.925
[[[0.05659157 0.17970598 0.3150443  0.2275533  0.2056486 ]]]
[500] loss: 59.412
[[[0.07691177 0.18088101 0.29859436 0.22774552 0.20260815]]]
[550] loss: 43.023
[[[0.09544624 0.18192899 0.28392747 0.2268057  0.20060207]]]
[600] loss: 30.708
[[[0.11203615 0.18301436 0.2708983  0.22512004 0.19938451]]]
[650] loss: 21.594
[[[0.12664992 0.18420726 0.25938973 0.22298607 0.19874549]]]
[700] loss: 14.955
[[[0.13934767 0.18551382 0.24930081 0.2206255  0.19851226]]]
[750] loss: 10.198
[[[0.15024935 0.18690367 0.24053685 0.21819925 0.19854674]]]
[800] loss: 6.844
[[[0.15950975 0.18833081 0.23300111 0.21582113 0.19874188]]]
[850] loss: 4.520
[[[0.16729963 0.18974732 0.2265922  0.21356872 0.19901773]]]
[900] loss: 2.936
[[[0.17379297 0.19111133 0.2212036  0.21149167 0.19931738]]]
[950] loss: 1.876
[[[0.17915842 0.19239034 0.21672578 0.20961851 0.19960271]]]
[1000] loss: 1.178
[[[0.18355425 0.19356234 0.21304895 0.20796107 0.19985096]]]
</code></pre></div></div>

<p>As we can see in this example, algorithm converges and parameter values are becoming close to the <strong>true solution</strong>, i.e.
<strong>[0.2, 0.2, 0.2, 0.2, 0.2]</strong>.</p>

    



<div class="post-tags">
  
    
    <a href="/tags.html#en">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">EN</span>
    </a>
  
    
    <a href="/tags.html#python">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">Python</span>
    </a>
  
    
    <a href="/tags.html#pytorch">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">PyTorch</span>
    </a>
  
    
    <a href="/tags.html#time-series">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">Time Series</span>
    </a>
  
</div>
  </div>

  
  <section class="comments">
    <h2>Comments</h2>
    
  <p>
    You are seeing this because your Disqus shortname is not properly set. To
    configure Disqus, you should edit your <code>_config.yml</code> to include
    either a <code>disqus.shortname</code> variable.
  </p>

  <p>
    If you do not wish to use Disqus, override the
    <code>comments.html</code> partial for this theme.
  </p>


  </section>

  <section class="related">
  <h2>Related Posts</h2>
  <ul class="posts-list">
    
      <li>
        <h3>
          <a href="/2020/09/27/path-chain.html">
            path.chain: Concise Structure for Chainable Paths
            <small>27 Sep 2020</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2020/09/17/s4-vs-vctrs.html">
            S4 Vs Vctrs
            <small>17 Sep 2020</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2020/05/10/eponge.html">
            eponge: Keep Your Environment Clean
            <small>10 May 2020</small>
          </a>
        </h3>
      </li>
    
  </ul>
</section>

</div>

    </main>

    <!-- Optional footer content -->
<!--a href="google.com">R-bloggers</a-->

  </body>
</html>
