<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on krzjoa</title><link>/tags/python/</link><description>Recent content in Python on krzjoa</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 21 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>How icy is sun, how fiery is snow? Playing with word embedding vectors</title><author>joachimiak.krzysztof@gmail.com (Krzysztof Joachimiak)</author><link>/2022/05/21/content/post/2022-05-21-how-icy-is-sun/</link><pubDate>Sat, 21 May 2022 00:00:00 +0000</pubDate><guid>/2022/05/21/content/post/2022-05-21-how-icy-is-sun/</guid><description>&lt;h1 id="how-icy-is-sun-how-fiery-is-snow-playing-with-word-embedding-vectors">How icy is sun, how fiery is snow? Playing with word embedding vectors&lt;/h1>
&lt;p>We all know old, good and hackneyed examples, that are typically used to intuitively explain, what the &lt;strong>word embedding&lt;/strong> technique is. We almost always come across a chart presenting a simplified, 2-dimensional vector representation of the words &lt;strong>queen&lt;/strong> and &lt;strong>king&lt;/strong>, which are distant from each other similarly as the words &lt;strong>woman&lt;/strong> and &lt;strong>man&lt;/strong>.&lt;/p>
&lt;p>Today, I&amp;rsquo;d like to go one step further and explore the meaning of the distance between two arbitrary selected vectors. It this particular case - distance between &lt;strong>ice&lt;/strong> and &lt;strong>fire&lt;/strong>.&lt;/p>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Assume for the moment we have an embedding in the 2-dimensional space. It&amp;rsquo;s not a realistic case, because in most cases such low-dimensional embedding wouldn&amp;rsquo;t fulfill its purpose. So, we have a bunch of vectors or points, described with two coordinates. We choose two such vectors, say &lt;strong>ice&lt;/strong> and &lt;strong>fire&lt;/strong>, as mentioned above.&lt;/p>
&lt;p>&lt;img src="/post/2022-05-21-how-icy-is-sun/word-embedding_files/plot_1.png" alt="Drawn using https://www.geogebra.org/m/JMMKv7cx">&lt;/p>
&lt;center> &lt;i>Drawn using: &lt;a href = "https://www.geogebra.org/m/JMMKv7cx">Geogebra&lt;/a>&lt;/i>&lt;/center>
&lt;p>Treating the straight line passing trough these points as a new axis, we project the rest of the points onto this line. &lt;strong>The midpoint&lt;/strong> between &amp;ldquo;ice&amp;rdquo; and &amp;ldquo;fire&amp;rdquo; can be treated as the origin (&amp;ldquo;point 0&amp;rdquo;) of the new axis.&lt;/p>
&lt;p>&lt;img src="/post/2022-05-21-how-icy-is-sun/word-embedding_files/plot_3.png" alt="Drawn using https://www.geogebra.org/m/JMMKv7cx">&lt;/p>
&lt;center> &lt;i>Drawn using: &lt;a href = "https://www.geogebra.org/m/JMMKv7cx">Geogebra&lt;/a>&lt;/i>&lt;/center>
&lt;p>I will call the &lt;strong>ice&lt;/strong> and &lt;strong>fire&lt;/strong> points &lt;strong>poles&lt;/strong>, to express that they show us, what is the expected meaning of being &amp;ldquo;&lt;em>negativemost&lt;/em>&amp;rdquo; and &amp;ldquo;&lt;em>positivemost&lt;/em>&amp;rdquo;.
Briefly - I expect that embedding vectors (poinst) for &amp;ldquo;cold&amp;rdquo; words such as &amp;ldquo;winter&amp;rdquo; will get a negative value on this new axis, while &amp;ldquo;warm&amp;rdquo; words - positive values.
In this context it means that positive-valued points are those ones, that have their projections on the &amp;ldquo;right&amp;rdquo; side of the of the new axis.&lt;/p>
&lt;p>Values obtained for each point are the distances from the projections to the midpoint (with sign).&lt;/p>
&lt;h2 id="math--code-behind">Math &amp;amp; code behind&lt;/h2>
&lt;p>One of the most convenient ways to get &lt;strong>embedding vectors&lt;/strong> for natural language is to use pre-trained models distributed with &lt;a href="https://spacy.io/">&lt;strong>spacy&lt;/strong>&lt;/a> library.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> numpy &lt;span style="color:#66d9ef">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> numpy.typing &lt;span style="color:#66d9ef">as&lt;/span> npt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> spacy
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> matplotlib.pyplot &lt;span style="color:#66d9ef">as&lt;/span> plt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> functools &lt;span style="color:#f92672">import&lt;/span> reduce
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> operator &lt;span style="color:#f92672">import&lt;/span> add
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Installing en_core_web_mdn&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlp &lt;span style="color:#f92672">=&lt;/span> spacy&lt;span style="color:#f92672">.&lt;/span>load(&lt;span style="color:#e6db74">&amp;#39;en_core_web_md&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>fire &lt;span style="color:#f92672">=&lt;/span> nlp(&lt;span style="color:#e6db74">&amp;#39;fire&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ice &lt;span style="color:#f92672">=&lt;/span> nlp(&lt;span style="color:#e6db74">&amp;#39;ice&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>len(fire&lt;span style="color:#f92672">.&lt;/span>vector)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>300
&lt;/code>&lt;/pre>
&lt;p>A couple of simple function calls, but there is a lot work done behind the scene. We can use &lt;strong>nlp&lt;/strong> object to process whole sentences (or documents) at once. For now, we only need to process single words.&lt;/p>
&lt;h3 id="midpoint---origin-of-the-new-axis">Midpoint - origin of the new axis&lt;/h3>
&lt;p>We will use a &lt;strong>midpoint&lt;/strong> between two initial points as the origin of the our new axis.
It can be calculated with the following formula:&lt;/p>
&lt;center>
$ M = (\frac{x + x_{1}}{2}, \frac{y + y_{1}}{2}, \frac{z + z_{1}}{2}, ...) $
&lt;/center>
&lt;p>Writing that as a function:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">midpoint&lt;/span>(x: npt&lt;span style="color:#f92672">.&lt;/span>NDArray, y: npt&lt;span style="color:#f92672">.&lt;/span>NDArray) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> npt&lt;span style="color:#f92672">.&lt;/span>NDArray:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (len(x) &lt;span style="color:#f92672">!=&lt;/span> len(y)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">raise&lt;/span> &lt;span style="color:#a6e22e">ValueError&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Vectors come from different spaces! &amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#39;x: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>len(x)&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> dimensions, y: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>len(y)&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> dimensions&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> (x &lt;span style="color:#f92672">+&lt;/span> y) &lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># midpoint(np.array([2, 3]), np.array([-1, 20]))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># midpoint(np.array([2, 3]), np.array([-1, 20, -45]))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>mid &lt;span style="color:#f92672">=&lt;/span> midpoint(fire&lt;span style="color:#f92672">.&lt;/span>vector, ice&lt;span style="color:#f92672">.&lt;/span>vector)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="plotting-function">Plotting function&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">plot&lt;/span>(points, lines, labels):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> points_x &lt;span style="color:#f92672">=&lt;/span> [x[&lt;span style="color:#ae81ff">0&lt;/span>] &lt;span style="color:#66d9ef">for&lt;/span> x &lt;span style="color:#f92672">in&lt;/span> points]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> points_y &lt;span style="color:#f92672">=&lt;/span> [x[&lt;span style="color:#ae81ff">1&lt;/span>] &lt;span style="color:#66d9ef">for&lt;/span> x &lt;span style="color:#f92672">in&lt;/span> points]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Lines&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> l &lt;span style="color:#f92672">in&lt;/span> lines:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>plot([l[&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>], l[&lt;span style="color:#ae81ff">1&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>]], [l[&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#ae81ff">1&lt;/span>], l[&lt;span style="color:#ae81ff">1&lt;/span>][&lt;span style="color:#ae81ff">1&lt;/span>]])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Labels&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> coords, lbl &lt;span style="color:#f92672">in&lt;/span> zip(points, labels):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>text(coords[&lt;span style="color:#ae81ff">0&lt;/span>], coords[&lt;span style="color:#ae81ff">1&lt;/span>], lbl)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Points&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>plot(points_x, points_y, &lt;span style="color:#e6db74">&amp;#39;.&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>grid()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>axhline(linewidth&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, color&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;black&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>axvline(linewidth&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, color&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;black&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>axis(&lt;span style="color:#e6db74">&amp;#39;equal&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>show()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Points lying on the straight line&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>A &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">10&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>B &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([&lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">18&lt;/span>]) &lt;span style="color:#75715e"># 18&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># a = np.array([2, 2])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># b = np.array([-2, -2])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>M &lt;span style="color:#f92672">=&lt;/span> midpoint(A, B)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>C &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">6&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>points &lt;span style="color:#f92672">=&lt;/span> [A, B, M, C]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lines &lt;span style="color:#f92672">=&lt;/span> [[A, B]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>labels &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;A&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;B&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;M&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;C&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plot(points, lines, labels)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="/post/2022-05-21-how-icy-is-sun/word-embedding_files/word-embedding_23_0.png" alt="png">&lt;/p>
&lt;p>As we can see, the line doesn&amp;rsquo;t pass trough the origin. We have to apply &lt;strong>affine transformation&lt;/strong> to shift the whole space, placing &lt;strong>midpoint AB&lt;/strong> at (0, 0). If we do so, we can easily find orthogonal projection of the point C on the line &amp;lsquo;marked&amp;rsquo; by the &lt;strong>B vector&lt;/strong>. After we shift the space, the segment $MB$ becomes a vector as it has its start in the origin.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>transform_matrix &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>eye(&lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>transform_matrix[&lt;span style="color:#ae81ff">0&lt;/span>:&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>M
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>transform_matrix
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>array([[ 1. , 0. , 2.5],
[ 0. , 1. , -10. ],
[ 0. , 0. , 1. ]])
&lt;/code>&lt;/pre>
&lt;p>If you&amp;rsquo;d like to know more details, how to construct the transformation matrix, see for example &lt;a href="https://articulatedrobotics.xyz/5-transformation_matrices/">Affine Transformation Matrices&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># tranformed_a = affine_transform_matrix @ np.vstack(a.T, [1])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">extend_with_one&lt;/span>(vec):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> vec &lt;span style="color:#f92672">=&lt;/span> vec[np&lt;span style="color:#f92672">.&lt;/span>newaxis]&lt;span style="color:#f92672">.&lt;/span>T
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>vstack([vec, [&lt;span style="color:#ae81ff">1&lt;/span>]])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>transposed &lt;span style="color:#f92672">=&lt;/span> [extend_with_one(p) &lt;span style="color:#66d9ef">for&lt;/span> p &lt;span style="color:#f92672">in&lt;/span> points]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>transformed &lt;span style="color:#f92672">=&lt;/span> [transform_matrix &lt;span style="color:#f92672">@&lt;/span> vec &lt;span style="color:#66d9ef">for&lt;/span> vec &lt;span style="color:#f92672">in&lt;/span> transposed]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Removing last dimension with &amp;#39;1&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>transformed &lt;span style="color:#f92672">=&lt;/span> [vec[&lt;span style="color:#ae81ff">0&lt;/span>:&lt;span style="color:#ae81ff">2&lt;/span>] &lt;span style="color:#66d9ef">for&lt;/span> vec &lt;span style="color:#f92672">in&lt;/span> transformed]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aff_A, aff_B, aff_M, aff_C &lt;span style="color:#f92672">=&lt;/span> transformed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lines &lt;span style="color:#f92672">=&lt;/span> [[aff_A, aff_B]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>labels &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;shifted_A&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;shifted_B&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;shifted_M&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;shifted_C&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plot(transformed, lines, labels)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="/post/2022-05-21-how-icy-is-sun/word-embedding_files/word-embedding_27_0.png" alt="png">&lt;/p>
&lt;h3 id="scalar-projection">Scalar projection&lt;/h3>
&lt;p>We want to compute the &lt;a href="https://en.wikipedia.org/wiki/Scalar_projection">scalar projection&lt;/a> of $\bf{v}$ on $\bf{w}$ using the left-hand side of the following equation:&lt;/p>
&lt;center>
${\hat{\bf{w}}}^{T}\bf{v} = |\bf{v}| cos\theta $
&lt;/center>
&lt;p>When $\theta$ is the angle between $\bf{w}$ and $\bf{v}$, and $\hat{\bf{w}}$ is the &lt;strong>unit vector&lt;/strong>, namely:&lt;/p>
&lt;center>
$\hat{\bf{w}} = \frac{\bf{w}}{|\bf{w}|} $
&lt;/center>
&lt;p>See also:&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://mathinsight.org/dot_product">The dot product&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=LyGKycYT2v0&amp;amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&amp;amp;index=9&amp;amp;t=216s">Dot products duality by 3Blue1Brown&lt;/a>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>unit_vec &lt;span style="color:#f92672">=&lt;/span> (aff_B) &lt;span style="color:#f92672">/&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>linalg&lt;span style="color:#f92672">.&lt;/span>norm(aff_B)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>scalar_product &lt;span style="color:#f92672">=&lt;/span> unit_vec&lt;span style="color:#f92672">.&lt;/span>T &lt;span style="color:#f92672">@&lt;/span> aff_C
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>scalar_product
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>array([[1.25389207]])
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># We compute projection of C to draw a plot&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>proj_C &lt;span style="color:#f92672">=&lt;/span> unit_vec &lt;span style="color:#f92672">*&lt;/span> scalar_product
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Plot &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>points &lt;span style="color:#f92672">=&lt;/span> transformed &lt;span style="color:#f92672">+&lt;/span> [proj_C]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lines &lt;span style="color:#f92672">=&lt;/span> [[aff_A, aff_B], [aff_C, proj_C]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>labels &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;shifted_A&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;shifted_B&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;shifted_mid_A_B&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;shifted_C&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;proj_C&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plot(points, lines, labels)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="/post/2022-05-21-how-icy-is-sun/word-embedding_files/word-embedding_33_0.png" alt="png">&lt;/p>
&lt;h2 id="axis-class">Axis class&lt;/h2>
&lt;p>Rewriting all as a function&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">axis&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self, negative_pole: npt&lt;span style="color:#f92672">.&lt;/span>NDArray, positive_pole: npt&lt;span style="color:#f92672">.&lt;/span>NDArray):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>dims &lt;span style="color:#f92672">=&lt;/span> len(negative_pole)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Original values&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>negative_pole &lt;span style="color:#f92672">=&lt;/span> negative_pole
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>positive_pole &lt;span style="color:#f92672">=&lt;/span> positive_pole
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>midpoint &lt;span style="color:#f92672">=&lt;/span> _midpoint(negative_pole, positive_pole)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Transformation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>transform &lt;span style="color:#f92672">=&lt;/span> _transformation_matrix(self&lt;span style="color:#f92672">.&lt;/span>dims, self&lt;span style="color:#f92672">.&lt;/span>midpoint)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>shifted_negative_pole &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>_shift(negative_pole)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>shifted_positive_pole &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>_shift(positive_pole)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>unit_vector &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>shifted_positive_pole &lt;span style="color:#f92672">/&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>linalg&lt;span style="color:#f92672">.&lt;/span>norm(self&lt;span style="color:#f92672">.&lt;/span>shifted_positive_pole) &lt;span style="color:#75715e"># shifted_midpoint is (0, 0, ...) &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __call__(self, vector: npt&lt;span style="color:#f92672">.&lt;/span>NDArray):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (len(vector) &lt;span style="color:#f92672">!=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>dims):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">raise&lt;/span> &lt;span style="color:#a6e22e">ValueError&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Vector length is &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>len(vector)&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">, but it should equal &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>self&lt;span style="color:#f92672">.&lt;/span>dims&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shifted_vector &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>_shift(vector)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> (self&lt;span style="color:#f92672">.&lt;/span>unit_vector&lt;span style="color:#f92672">.&lt;/span>T &lt;span style="color:#f92672">@&lt;/span> shifted_vector)[&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">plot&lt;/span>(self, &lt;span style="color:#f92672">*&lt;/span>args, title &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Embedding vectors&amp;#34;&lt;/span>, figsize &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#ae81ff">10&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> poles &lt;span style="color:#f92672">=&lt;/span> {&lt;span style="color:#e6db74">&amp;#39;negative&amp;#39;&lt;/span>: {&lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;Negative pole&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;blue&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;positive&amp;#39;&lt;/span>: {&lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;Positive pole&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>:&lt;span style="color:#e6db74">&amp;#39;red&amp;#39;&lt;/span>}}):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Init plot&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fig, ax &lt;span style="color:#f92672">=&lt;/span> plt&lt;span style="color:#f92672">.&lt;/span>subplots(figsize&lt;span style="color:#f92672">=&lt;/span>figsize, constrained_layout&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>set(title&lt;span style="color:#f92672">=&lt;/span>title)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Horizontal line &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> neg_value &lt;span style="color:#f92672">=&lt;/span> self(self&lt;span style="color:#f92672">.&lt;/span>negative_pole)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pos_value &lt;span style="color:#f92672">=&lt;/span> self(self&lt;span style="color:#f92672">.&lt;/span>positive_pole)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> all_values &lt;span style="color:#f92672">=&lt;/span> reduce(add, [a[&lt;span style="color:#e6db74">&amp;#39;values&amp;#39;&lt;/span>] &lt;span style="color:#66d9ef">for&lt;/span> a &lt;span style="color:#f92672">in&lt;/span> args])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> all_values &lt;span style="color:#f92672">=&lt;/span> all_values &lt;span style="color:#f92672">+&lt;/span> [neg_value, pos_value]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>plot(all_values, np&lt;span style="color:#f92672">.&lt;/span>zeros_like(all_values), &lt;span style="color:#e6db74">&amp;#34;-o&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> color&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;k&amp;#34;&lt;/span>, markerfacecolor&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;w&amp;#34;&lt;/span>) &lt;span style="color:#75715e"># Baseline and markers on it.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Generate colours if not defined&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> group &lt;span style="color:#f92672">in&lt;/span> args:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> values &lt;span style="color:#f92672">=&lt;/span> group[&lt;span style="color:#e6db74">&amp;#39;values&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels &lt;span style="color:#f92672">=&lt;/span> group[&lt;span style="color:#e6db74">&amp;#39;labels&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> color &lt;span style="color:#f92672">=&lt;/span> group[&lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> levels &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>tile([&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> int(np&lt;span style="color:#f92672">.&lt;/span>ceil(len(values)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">6&lt;/span>)))[:len(values)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>vlines(values, &lt;span style="color:#ae81ff">0&lt;/span>, levels, color&lt;span style="color:#f92672">=&lt;/span>color)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> vert &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([&lt;span style="color:#e6db74">&amp;#39;top&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;bottom&amp;#39;&lt;/span>])[(levels &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>astype(int)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> d, l, r, va &lt;span style="color:#f92672">in&lt;/span> zip(values, levels, labels, vert):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>annotate(r, xy&lt;span style="color:#f92672">=&lt;/span>(d, l), xytext&lt;span style="color:#f92672">=&lt;/span>(&lt;span style="color:#ae81ff">1&lt;/span>, np&lt;span style="color:#f92672">.&lt;/span>sign(l)&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> textcoords&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;offset points&amp;#34;&lt;/span>, va&lt;span style="color:#f92672">=&lt;/span>va, ha&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;right&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Show poles&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> neg_pole &lt;span style="color:#f92672">=&lt;/span> poles[&lt;span style="color:#e6db74">&amp;#39;negative&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pos_pole &lt;span style="color:#f92672">=&lt;/span> poles[&lt;span style="color:#e6db74">&amp;#39;positive&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>vlines(neg_value, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, neg_pole[&lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>annotate(neg_pole[&lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>], xy&lt;span style="color:#f92672">=&lt;/span>(neg_value, &lt;span style="color:#ae81ff">4&lt;/span>), xytext&lt;span style="color:#f92672">=&lt;/span>(&lt;span style="color:#ae81ff">4&lt;/span>, np&lt;span style="color:#f92672">.&lt;/span>sign(&lt;span style="color:#ae81ff">4&lt;/span>)&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> textcoords&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;offset points&amp;#34;&lt;/span>, va&lt;span style="color:#f92672">=&lt;/span>va, ha&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;right&amp;#34;&lt;/span>, weight&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;bold&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>vlines(pos_value, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>, color&lt;span style="color:#f92672">=&lt;/span>pos_pole[&lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>annotate(pos_pole[&lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>], xy&lt;span style="color:#f92672">=&lt;/span>(pos_value, &lt;span style="color:#ae81ff">4&lt;/span>), xytext&lt;span style="color:#f92672">=&lt;/span>(&lt;span style="color:#ae81ff">4&lt;/span>, np&lt;span style="color:#f92672">.&lt;/span>sign(&lt;span style="color:#ae81ff">4&lt;/span>)&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> textcoords&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;offset points&amp;#34;&lt;/span>, va&lt;span style="color:#f92672">=&lt;/span>va, ha&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;right&amp;#34;&lt;/span>, weight&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;bold&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Show the plot&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>yaxis&lt;span style="color:#f92672">.&lt;/span>set_visible(&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>spines[[&lt;span style="color:#e6db74">&amp;#34;left&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;top&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;right&amp;#34;&lt;/span>]]&lt;span style="color:#f92672">.&lt;/span>set_visible(&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ax&lt;span style="color:#f92672">.&lt;/span>margins(y&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>show()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">_shift&lt;/span>(self, vector: npt&lt;span style="color:#f92672">.&lt;/span>NDArray):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> extended_vector &lt;span style="color:#f92672">=&lt;/span> _extend_with_one(vector)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> (self&lt;span style="color:#f92672">.&lt;/span>transform &lt;span style="color:#f92672">@&lt;/span> extended_vector)[&lt;span style="color:#ae81ff">0&lt;/span>:self&lt;span style="color:#f92672">.&lt;/span>dims]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">_extend_with_one&lt;/span>(vector: npt&lt;span style="color:#f92672">.&lt;/span>NDArray) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> npt&lt;span style="color:#f92672">.&lt;/span>NDArray:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> vector &lt;span style="color:#f92672">=&lt;/span> vector[np&lt;span style="color:#f92672">.&lt;/span>newaxis]&lt;span style="color:#f92672">.&lt;/span>T
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>vstack([vector, [&lt;span style="color:#ae81ff">1&lt;/span>]])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">_transformation_matrix&lt;/span>(dims: int, midpoint: npt&lt;span style="color:#f92672">.&lt;/span>NDArray) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> npt&lt;span style="color:#f92672">.&lt;/span>NDArray:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mat &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>eye(dims &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mat[&lt;span style="color:#ae81ff">0&lt;/span>:dims, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>midpoint
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> mat
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">_midpoint&lt;/span>(x: npt&lt;span style="color:#f92672">.&lt;/span>NDArray, y: npt&lt;span style="color:#f92672">.&lt;/span>NDArray) &lt;span style="color:#f92672">-&amp;gt;&lt;/span> npt&lt;span style="color:#f92672">.&lt;/span>NDArray:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (len(x) &lt;span style="color:#f92672">!=&lt;/span> len(y)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">raise&lt;/span> &lt;span style="color:#a6e22e">ValueError&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Vectors come from different spaces! &amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#39;x: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>len(x)&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> dimensions, y: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>len(y)&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> dimensions&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> (x &lt;span style="color:#f92672">+&lt;/span> y) &lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Last quick check with a simplified example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Points lying on the straight line&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>A &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">10&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>B &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([&lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">18&lt;/span>]) &lt;span style="color:#75715e"># 18&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>C &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">6&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axis_a_b &lt;span style="color:#f92672">=&lt;/span> axis(A, B)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>points &lt;span style="color:#f92672">=&lt;/span> [A, B, C, axis_a_b&lt;span style="color:#f92672">.&lt;/span>midpoint]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>shifted_points &lt;span style="color:#f92672">=&lt;/span> [axis_a_b&lt;span style="color:#f92672">.&lt;/span>_shift(p) &lt;span style="color:#66d9ef">for&lt;/span> p &lt;span style="color:#f92672">in&lt;/span> points]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>proj_C &lt;span style="color:#f92672">=&lt;/span> axis_a_b(C) &lt;span style="color:#f92672">*&lt;/span> axis_a_b&lt;span style="color:#f92672">.&lt;/span>unit_vector
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>shifted_points &lt;span style="color:#f92672">=&lt;/span> shifted_points &lt;span style="color:#f92672">+&lt;/span> [proj_C]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>shifted_A, shifted_B, shifted_C, shifted_M, _ &lt;span style="color:#f92672">=&lt;/span> shifted_points
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lines &lt;span style="color:#f92672">=&lt;/span> [[shifted_A, shifted_B], [shifted_C, proj_C]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>labels &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;shifted_A&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;shifted_B&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;shifted_C&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;shifted_M&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;proj_C&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plot(shifted_points, lines, labels)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="word-embedding_files/word-embedding_38_0.png" alt="png">&lt;/p>
&lt;h2 id="experiment-with-embeddings">Experiment with embeddings&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>ice_fire_axis &lt;span style="color:#f92672">=&lt;/span> axis(ice&lt;span style="color:#f92672">.&lt;/span>vector, fire&lt;span style="color:#f92672">.&lt;/span>vector)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Ice&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ice_value &lt;span style="color:#f92672">=&lt;/span> ice_fire_axis(ice&lt;span style="color:#f92672">.&lt;/span>vector)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Fire&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>fire_value &lt;span style="color:#f92672">=&lt;/span> ice_fire_axis(fire&lt;span style="color:#f92672">.&lt;/span>vector)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>cold &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;polar&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;snow&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;winter&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;fridge&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Antarctica&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;freeze&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>warm &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;tropical&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;sun&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;summer&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;oven&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Africa&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;flame&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>cold_vecs &lt;span style="color:#f92672">=&lt;/span> [nlp(w)&lt;span style="color:#f92672">.&lt;/span>vector &lt;span style="color:#66d9ef">for&lt;/span> w &lt;span style="color:#f92672">in&lt;/span> cold]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>warm_vecs &lt;span style="color:#f92672">=&lt;/span> [nlp(w)&lt;span style="color:#f92672">.&lt;/span>vector &lt;span style="color:#66d9ef">for&lt;/span> w &lt;span style="color:#f92672">in&lt;/span> warm]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>cold_values &lt;span style="color:#f92672">=&lt;/span> [ice_fire_axis(p) &lt;span style="color:#66d9ef">for&lt;/span> p &lt;span style="color:#f92672">in&lt;/span> cold_vecs]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>warm_values &lt;span style="color:#f92672">=&lt;/span> [ice_fire_axis(p) &lt;span style="color:#66d9ef">for&lt;/span> p &lt;span style="color:#f92672">in&lt;/span> warm_vecs]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>warm_values
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>[-0.179010129140625,
0.7686063030627324,
0.21483235444847368,
0.5769307333087565,
0.830039105765312,
2.751032938467553]
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>all_values &lt;span style="color:#f92672">=&lt;/span> cold_values &lt;span style="color:#f92672">+&lt;/span> warm_values &lt;span style="color:#f92672">+&lt;/span> [ice_value, fire_value]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>all_labels &lt;span style="color:#f92672">=&lt;/span> cold &lt;span style="color:#f92672">+&lt;/span> warm
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>ice_fire_axis&lt;span style="color:#f92672">.&lt;/span>plot(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#39;values&amp;#39;&lt;/span>: cold_values, &lt;span style="color:#e6db74">&amp;#39;labels&amp;#39;&lt;/span>: cold, &lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;tab:blue&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#e6db74">&amp;#39;values&amp;#39;&lt;/span>: warm_values, &lt;span style="color:#e6db74">&amp;#39;labels&amp;#39;&lt;/span>: warm, &lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;tab:red&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> poles &lt;span style="color:#f92672">=&lt;/span> {&lt;span style="color:#e6db74">&amp;#39;negative&amp;#39;&lt;/span>: {&lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;ice&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;blue&amp;#39;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;positive&amp;#39;&lt;/span>: {&lt;span style="color:#e6db74">&amp;#39;label&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;ice&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;red&amp;#39;&lt;/span>}}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="/post/2022-05-21-how-icy-is-sun/word-embedding_files/word-embedding_46_0.png" alt="png">&lt;/p>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;p>As we can see, in this case the meaning of the distance between &amp;ldquo;ice&amp;rdquo; and &amp;ldquo;fire&amp;rdquo; looks as expected. &amp;ldquo;Cold words&amp;rdquo; are closer to the &lt;em>negative pole&lt;/em> while the &amp;ldquo;warm words* - to the &lt;em>positive pole&lt;/em>.&lt;/p>
&lt;p>To do a similar experiment by yourself, you can use my &lt;a href="https://github.com/krzjoa/salto">salto&lt;/a> package.&lt;/p></description></item><item><title>Time Series &amp; PyTorch - Training network to compute moving average</title><author>joachimiak.krzysztof@gmail.com (Krzysztof Joachimiak)</author><link>/2019/12/28/content/post/2019-12-28-pytorch-ts-v1/2019-12-28-pytorch-ts-v1/</link><pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate><guid>/2019/12/28/content/post/2019-12-28-pytorch-ts-v1/2019-12-28-pytorch-ts-v1/</guid><description>&lt;p>When it comes to applying neural networks to Time Series processing (or other kind of sequential data), first words that we&amp;rsquo;ll probably think of are &lt;strong>recurrent&lt;/strong> and &lt;strong>convolutional&lt;/strong> layers. That&amp;rsquo;s absolutely right! In this post we&amp;rsquo;ll pass, step-by-step, through one of the simpliest examples of convolutional layer application i.e. training network to compute moving average. Such example may seem to not be practical, however its simplicity allows us to trace whole process and understand, how to control network&amp;rsquo;s behaviour, to model the way the network works.&lt;/p>
&lt;h3 id="1-downloading-the-data">1. Downloading the data&lt;/h3>
&lt;p>First thing we have to do is to download or create fake time serie dataset. Let get a Shampoo sales dataset published by Rob Hyndman in his &lt;strong>R package&lt;/strong> &lt;code>fma&lt;/code> (which was a software appedix for the book &lt;em>Forecasting: Methods and Applications&lt;/em>). Originally this dataset can be found inside R script, but as we work with a Python libary PyTorch, it be better for us to load this data from csv file. Such file can be found, for instance, &lt;a href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/shampoo.csv">here&lt;/a>. Supposing we work in &lt;strong>Jupyter Notebook&lt;/strong> on Linux, we can fetch this data running following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">## Download dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#960050;background-color:#1e0010">!&lt;/span>wget https:&lt;span style="color:#f92672">//&lt;/span>raw&lt;span style="color:#f92672">.&lt;/span>githubusercontent&lt;span style="color:#f92672">.&lt;/span>com&lt;span style="color:#f92672">/&lt;/span>jbrownlee&lt;span style="color:#f92672">/&lt;/span>Datasets&lt;span style="color:#f92672">/&lt;/span>master&lt;span style="color:#f92672">/&lt;/span>shampoo&lt;span style="color:#f92672">.&lt;/span>csv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="2-loading-data-and-simple-visualization">2. Loading data and simple visualization&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> matplotlib.pyplot &lt;span style="color:#66d9ef">as&lt;/span> plt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#34;shampoo.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>plot(data[&lt;span style="color:#e6db74">&amp;#39;Sales&amp;#39;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>show()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="/post/2019-12-28-pytorch-ts-v1/plot.png" alt="png">&lt;/p>
&lt;p>In this plot we can see an increasing trend, but in this excercise, data characterics make no diffeence for us.&lt;/p>
&lt;h3 id="3-1-d-convolution-in-pytorch-lightning-quick-intro-or-reminder">3. 1-d convolution in PyTorch: lightning-quick intro (or reminder)&lt;/h3>
&lt;p>In the case of &lt;strong>univariate time series&lt;/strong>, one-dimensional convolution is a sliding window applied over time series, an operation which consist of multiplications and additions. It was intuitively illustrated on the gif below.&lt;/p>
&lt;center>
&lt;img src="/post/2019-12-28-pytorch-ts-v1/conv1d.gif" width="400">
Source: https://blog.floydhub.com/reading-minds-with-deep-learning/
&lt;/center>
&lt;p>As you can see, output depend on input and &lt;strong>kernel&lt;/strong> values. Defining proper kernel, we can apply the operation we want. For example, using a &lt;strong>(0.5, 0.5)&lt;/strong> kernel, it will give us a two-element moving average. To test that, let&amp;rsquo;s do a simple experiment.&lt;/p>
&lt;h3 id="4-computing-moving-average-with-pandas">4. Computing moving average with &lt;code>pandas&lt;/code>&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>ts &lt;span style="color:#f92672">=&lt;/span> data&lt;span style="color:#f92672">.&lt;/span>Sales
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ts&lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">10&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>0 266.0
1 145.9
2 183.1
3 119.3
4 180.3
5 168.5
6 231.8
7 224.5
8 192.8
9 122.9
Name: Sales, dtype: float64
&lt;/code>&lt;/pre>
&lt;p>Using &lt;code>pandas&lt;/code>, we can compute moving average by combining &lt;code>rolling&lt;/code> and &lt;code>mean&lt;/code> method calls. We use &lt;code>head&lt;/code> method as well, to limit the output. By the way, this example shows the object-oriented nature of &lt;code>pandas&lt;/code>, which allows us to chain following methodc calls. Other fact that is worth to mention is a &lt;strong>NaN&lt;/strong> occurrence in the first row. It&amp;rsquo;s because we can&amp;rsquo;t compute moving avearge for the first element if we haven&amp;rsquo;t added any padding on the beginnng of the array; moreover, &lt;code>pandas&lt;/code> keeps the input&amp;rsquo;s length, so the first element has no value.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># rolling(2) means that we use a sliding window of length 2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ts&lt;span style="color:#f92672">.&lt;/span>rolling(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>mean()&lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">10&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>0 NaN
1 205.95
2 164.50
3 151.20
4 149.80
5 174.40
6 200.15
7 228.15
8 208.65
9 157.85
Name: Sales, dtype: float64
&lt;/code>&lt;/pre>
&lt;h3 id="5-computing-moving-average-with-pytorch">5. Computing moving average with PyTorch&lt;/h3>
&lt;p>Now, let&amp;rsquo;s reproduce this result using 1-dimensional convolution from PyTorch.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torch.nn &lt;span style="color:#66d9ef">as&lt;/span> nn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torch.optim &lt;span style="color:#66d9ef">as&lt;/span> optim
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torch.nn.functional &lt;span style="color:#66d9ef">as&lt;/span> F
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>print(len(ts))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>36
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>ts_tensor &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor(ts)&lt;span style="color:#f92672">.&lt;/span>reshape(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let&amp;rsquo;s stop here for a moment. If you are not familiar with deep learning frameworks, you would be quite confused because of this &lt;code>reshape&lt;/code> operation. What did we do above? We created a &lt;strong>3-dimensional tensor&lt;/strong>; each number in &lt;code>reshape&lt;/code> function describes respectively:&lt;/p>
&lt;ol>
&lt;li>number of samples&lt;/li>
&lt;li>number of channels&lt;/li>
&lt;li>length of time series&lt;/li>
&lt;/ol>
&lt;p>Meaning of this values requires some explanation.&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Number of samples&lt;/strong> is the number of time series we are working on. As we want to perform computations for one time series only, the value must equal one.&lt;/li>
&lt;li>&lt;strong>Number of channels&lt;/strong> is is the number of &lt;strong>features&lt;/strong> or (independent) &lt;strong>variables&lt;/strong>. We don&amp;rsquo;t have any parallel variables contaning information about, say, temperature or population. It&amp;rsquo;s clear that this value must equal one too.&lt;/li>
&lt;li>&lt;strong>Length of time series&lt;/strong>. Accordingly to Python tensor reshaping convention, minus one means &lt;em>infer value for this dimension&lt;/em>. If one-dimensional time series length has 36 elements, after reshaping it to three-dimensional tensor with &lt;em>number_of_samples&lt;/em> = 1 and &lt;em>number_of_channels&lt;/em> = 1, the last value will be equal to 36.&lt;/li>
&lt;/ol>
&lt;p>We have to do the same with the kernel.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>kernel &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#ae81ff">0.5&lt;/span>, &lt;span style="color:#ae81ff">0.5&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kernel_tensor &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor(kernel)&lt;span style="color:#f92672">.&lt;/span>reshape(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>F&lt;span style="color:#f92672">.&lt;/span>conv1d(ts_tensor, kernel_tensor)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>tensor([[[205.9500, 164.5000, 151.2000, 149.8000, 174.4000, 200.1500, 228.1500,
208.6500, 157.8500, 229.7000, 261.2000, 190.1000, 171.9000, 179.8000,
241.7000, 232.3500, 239.2000, 256.5000, 264.8000, 296.7500, 355.7500,
343.0500, 303.4000, 341.0000, 390.0500, 378.1500, 377.6000, 420.3000,
419.3500, 506.4500, 491.5500, 544.8000, 578.6500, 528.3000, 614.1000]]])
&lt;/code>&lt;/pre>
&lt;p>As we can observe, the result is identical with values returned by &lt;code>pandas&lt;/code> methods. The only difference is lack of &lt;strong>NaN&lt;/strong> on the beginning.&lt;/p>
&lt;h3 id="6-learning-a-network-which-computes-moving-average">6. Learning a network, which computes moving average&lt;/h3>
&lt;p>Now, let&amp;rsquo;s get to the point and train the network on the fully controllable example. I&amp;rsquo;ve called in this manner to distinguish it from the real-life ones. In most cases, when we train a machine learning model, we don&amp;rsquo;t know the optimal parameter values. We are just trying to choose the best ones, but have no guarantee that they are globally optimal. Here, the optimal kernel value is known and should equal &lt;strong>[0.2, 0.2, 0.2, 0.2, 0.2]&lt;/strong>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>X &lt;span style="color:#f92672">=&lt;/span> data&lt;span style="color:#f92672">.&lt;/span>Sales
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>X_tensor &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor(X)&lt;span style="color:#f92672">.&lt;/span>reshape(&lt;span style="color:#ae81ff">1&lt;/span>,&lt;span style="color:#ae81ff">1&lt;/span>,&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the step below, we are preparing &lt;strong>targets&lt;/strong> (&lt;strong>labels&lt;/strong>), which equals to the five-element moving average.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>y &lt;span style="color:#f92672">=&lt;/span> data&lt;span style="color:#f92672">.&lt;/span>Sales&lt;span style="color:#f92672">.&lt;/span>rolling(&lt;span style="color:#ae81ff">5&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>mean()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y &lt;span style="color:#f92672">=&lt;/span> y[&lt;span style="color:#ae81ff">4&lt;/span>:, ]&lt;span style="color:#f92672">.&lt;/span>to_numpy()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_tensor &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>Tensor(y)&lt;span style="color:#f92672">.&lt;/span>reshape(&lt;span style="color:#ae81ff">1&lt;/span>,&lt;span style="color:#ae81ff">1&lt;/span>,&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>y_tensor
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>tensor([[[178.9200, 159.4200, 176.6000, 184.8800, 199.5800, 188.1000, 221.7000,
212.5200, 206.4800, 197.8200, 215.2600, 202.6200, 203.7200, 222.2600,
237.5600, 256.2600, 259.5800, 305.6200, 301.1200, 324.3800, 331.6000,
361.7000, 340.5600, 375.5200, 387.3200, 406.8600, 433.8800, 452.2200,
500.7600, 515.5600, 544.3400, 558.6200]]])
&lt;/code>&lt;/pre>
&lt;p>We are building a one-layer convlutional neural network. It&amp;rsquo;s good to highlight, that &lt;strong>we don&amp;rsquo;t use any nonlinear activation function&lt;/strong>. Last numerical value describes the length of the kernel, &lt;em>padding_mode = &amp;lsquo;valid&amp;rsquo;&lt;/em> means that we don&amp;rsquo;t add any padding to the input, so we have to expect that output will be &amp;ldquo;trimmed&amp;rdquo;.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Building a network&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>net &lt;span style="color:#f92672">=&lt;/span> nn&lt;span style="color:#f92672">.&lt;/span>Conv1d(&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, padding_mode &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;valid&amp;#34;&lt;/span>, bias &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Kernel is already initialized with, assume it for simplicity, &lt;em>random&lt;/em> values.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Initial values&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>net&lt;span style="color:#f92672">.&lt;/span>weight&lt;span style="color:#f92672">.&lt;/span>data&lt;span style="color:#f92672">.&lt;/span>numpy()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>array([[[-0.26035744, -0.03702363, 0.36730862, -0.02416185,
0.13382941]]], dtype=float32)
&lt;/code>&lt;/pre>
&lt;p>We can perfom a convolution operation using this random value, calling &lt;strong>net.forward()&lt;/strong> or simply &lt;strong>net()&lt;/strong> (because Conv1d layer is a &lt;a href="https://stackoverflow.com/questions/5824881/python-call-special-method-practical-example/5826283">callable object&lt;/a>). This two operations are equivalent.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>net(X_tensor)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>tensor([[[ 13.8443, 17.2486, 41.0878, 48.5995, 52.3392, 41.7977, 44.2186,
-3.6977, 90.3636, 39.1391, 1.3805, 30.8177, 40.0606, 87.4678,
28.7942, 62.3456, 54.0152, 77.8429, 61.6129, 104.4986, 43.2576,
56.9010, 74.8728, 111.2240, 54.3756, 83.8423, 115.3400, 72.0719,
172.1338, 61.6583, 151.8888, 115.7389]]],
grad_fn=&amp;lt;SqueezeBackward1&amp;gt;)
&lt;/code>&lt;/pre>
&lt;p>We are initializing an optimizer object. I highly encourage you to experiment and start with &lt;strong>SGD&lt;/strong> which may do not converge.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Training a network&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimizer &lt;span style="color:#f92672">=&lt;/span> optim&lt;span style="color:#f92672">.&lt;/span>Adam(net&lt;span style="color:#f92672">.&lt;/span>parameters(), lr&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.01&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here, he have only one example so it does not make sense to divide training into epochs&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>running_loss &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> iteration &lt;span style="color:#f92672">in&lt;/span> range(&lt;span style="color:#ae81ff">1001&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Zeroing gradients. For more,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># see: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> optimizer&lt;span style="color:#f92672">.&lt;/span>zero_grad()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Forward propagation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> outputs &lt;span style="color:#f92672">=&lt;/span> net(X_tensor)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Mean squared error&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loss_value &lt;span style="color:#f92672">=&lt;/span> torch&lt;span style="color:#f92672">.&lt;/span>mean((outputs &lt;span style="color:#f92672">-&lt;/span> y_tensor)&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Computing gradients&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loss_value&lt;span style="color:#f92672">.&lt;/span>backward()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Changing network parameters with optimizer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> optimizer&lt;span style="color:#f92672">.&lt;/span>step()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Extractin loss value from tensor&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> running_loss &lt;span style="color:#f92672">+=&lt;/span> loss_value&lt;span style="color:#f92672">.&lt;/span>item()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> iteration &lt;span style="color:#f92672">%&lt;/span> &lt;span style="color:#ae81ff">50&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#39;[&lt;/span>&lt;span style="color:#e6db74">%d&lt;/span>&lt;span style="color:#e6db74">] loss: &lt;/span>&lt;span style="color:#e6db74">%.3f&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span> &lt;span style="color:#f92672">%&lt;/span> (iteration, loss_value&lt;span style="color:#f92672">.&lt;/span>item()))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(net&lt;span style="color:#f92672">.&lt;/span>weight&lt;span style="color:#f92672">.&lt;/span>data&lt;span style="color:#f92672">.&lt;/span>numpy())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>[0] loss: 65233.992
[[[-0.25035745 -0.02702364 0.3773086 -0.01416185 0.14382942]]]
[50] loss: 766.905
[[[-0.10564941 0.11878491 0.5043409 0.1344783 0.27711937]]]
[100] loss: 543.447
[[[-0.0883443 0.13628373 0.48577502 0.15751141 0.2710214 ]]]
[150] loss: 426.048
[[[-0.0724933 0.14859414 0.45826674 0.1760565 0.25820443]]]
[200] loss: 328.581
[[[-0.05417605 0.15856615 0.4295487 0.1921131 0.2450627 ]]]
[250] loss: 251.294
[[[-0.03332883 0.1663786 0.40218312 0.20528159 0.23343563]]]
[300] loss: 191.313
[[[-0.01093305 0.17196906 0.37692106 0.21512112 0.2236998 ]]]
[350] loss: 144.881
[[[0.01206546 0.17570996 0.3540248 0.22179407 0.21593276]]]
[400] loss: 108.854
[[[0.03480669 0.1781194 0.33345547 0.225752 0.2099969 ]]]
[450] loss: 80.925
[[[0.05659157 0.17970598 0.3150443 0.2275533 0.2056486 ]]]
[500] loss: 59.412
[[[0.07691177 0.18088101 0.29859436 0.22774552 0.20260815]]]
[550] loss: 43.023
[[[0.09544624 0.18192899 0.28392747 0.2268057 0.20060207]]]
[600] loss: 30.708
[[[0.11203615 0.18301436 0.2708983 0.22512004 0.19938451]]]
[650] loss: 21.594
[[[0.12664992 0.18420726 0.25938973 0.22298607 0.19874549]]]
[700] loss: 14.955
[[[0.13934767 0.18551382 0.24930081 0.2206255 0.19851226]]]
[750] loss: 10.198
[[[0.15024935 0.18690367 0.24053685 0.21819925 0.19854674]]]
[800] loss: 6.844
[[[0.15950975 0.18833081 0.23300111 0.21582113 0.19874188]]]
[850] loss: 4.520
[[[0.16729963 0.18974732 0.2265922 0.21356872 0.19901773]]]
[900] loss: 2.936
[[[0.17379297 0.19111133 0.2212036 0.21149167 0.19931738]]]
[950] loss: 1.876
[[[0.17915842 0.19239034 0.21672578 0.20961851 0.19960271]]]
[1000] loss: 1.178
[[[0.18355425 0.19356234 0.21304895 0.20796107 0.19985096]]]
&lt;/code>&lt;/pre>
&lt;p>As we can see in this example, algorithm converges and parameter values are becoming close to the &lt;strong>true solution&lt;/strong>, i.e.
&lt;strong>[0.2, 0.2, 0.2, 0.2, 0.2]&lt;/strong>.&lt;/p></description></item></channel></rss>